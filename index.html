<!DOCTYPE html>
<html> 
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SOS-SLAM: Segmentation for Open-Set SLAM in Unstructured Environments.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SOS-SLAM: Segmentation for Open-Set SLAM in Unstructured Environments</title> 

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SOS-SLAM: Segmentation for Open-Set SLAM in Unstructured Environments</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href=" https://www.linkedin.com/in/jouko-kinnari/">Jouko Kinnari</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a href="https://annikathomas.com">Annika Thomas</a><sup>*2</sup>,</span>
            <span class="author-block">
              <a href="https://plusk01.github.io/">Parker Lusk</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/kkondo/?locale=en_US">Kota Kondo</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.mit.edu/~jhow/">Jonathan How</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
            <span class="author-block"><sup>1</sup>Saab Finland,</span>
            <span class="author-block"><sup>2</sup>Massachusetts Institute of Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1b7TZhalVafbWrrrUepgkYl8vfeb106AZ/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://www.dropbox.com/scl/fo/he8rq4ucgywmoha2y95zp/h?rlkey=cwt7q9whl4koelo4raiaptlfg&dl=0"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<div class="container is-max-desktop">
  <div class="column has-text-centered">
    <p class="release-date">Code is prepared and awaiting corporate approval to be released by February 1, 2024.</p>
  </div>
</div>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Image Section -->
      <div class="image-section">
        <img src="./static/images/SOS SLAM V3-1.png" alt="Example Image">
        <p class="caption">SOS-SLAM is a pipeline that provides maps less than 0.4% the size of benchmark maps and localizes up to 14x faster than feature-based approaches in unstructured environments. The front end mapping pipeline utilizes the vehicle odometry sensor along with camera images to perform SLAM and generate compact vehicle maps from object masks. The frame alignment pipeline offsets windows and uses our data association algorithm to filter the most likely correspondences.</p>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- First Video -->
      <div class="video-container">
        <video id="teaser1" autoplay muted loop playsinline>
          <source src="./static/videos/SOSSLAMdemo (2).mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">The Batvik dataset includes a drone flying over unstructured terrain in coastal Finland.</span>
        </h2>
      </div>
<!-- 
      <!-- Second Video -->
<!--       <div class="video-container has-text-centered"> -->
<!--         <video id="teaser2" autoplay muted loop playsinline> -->
<!--           <source src="./static/videos/mapsegs3.mp4" type="video/mp4"> -->
<!--         </video> -->
<!--         <h2 class="subtitle has-text-centered"> -->
<!--           <span class="dnerf">SOS-SLAM creates an object-based map tracking segments across image frames.</span> -->
<!--         </h2> -->
<!--       </div> -->
<!--     </div> -->
<!--   </div> -->
<!-- </section> --> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present a novel framework for open-set Simultaneous Localization and Mapping (SLAM) in unstructured environments that uses segmentation to create a map of objects
            and geometric relationships between objects for localization.
            Our system consists of 1) a front-end mapping pipeline using
            a zero-shot segmentation model to extract object masks from
            images and track them across frames to generate an object-
            based map and 2) a frame alignment pipeline that uses the
            geometric consistency of objects to efficiently localize within
            maps taken in a variety of conditions. This approach is shown
            to be more robust to changes in lighting and appearance than
            traditional feature-based SLAM systems or global descriptor
            methods. This is established by evaluating SOS-SLAM on the
            B ̊atvik seasonal dataset which includes drone flights collected
            over a coastal plot of southern Finland during different seasons and lighting conditions. Across flights during the same
            lighting and environmental conditions, our approach achieves
            2-3 times higher recall than benchmark methods with preci-
            sion of 1.0. SOS-SLAM localizes within a reference map up
            to 16x faster than other feature-based approaches and has a
            map size less than 0.4% the size of the most compact other
            maps. When considering localization performance from varying viewpoints, our approach outperforms all benchmarks
            from the same viewpoint and most benchmarks from different viewpoints. SOS-SLAM is a promising new approach for
            SLAM in unstructured environments that is robust to changes in lighting and appearance and is more computationally
            efficient than other approaches.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

<section class="hero teaser">
  <div class="container is-max-desktop is-centered">
    <div class="hero-body">
      <!-- First Video -->
      <div class="video-container">
        <h2 class="title is-3">Batvik Seasonal Dataset</h2>
        <video id="teaser1" autoplay muted loop playsinline>
          <source src="./static/videos/combined_compressed.mp4" type="video/mp4">
        </video>
        <div class="content has-text-justified">
          <p>
            We introduce the Batvik seasonal dataset which includes ˚
            six drone flights that travel a distance of approximately 3.5 km over a coastal plot in southern Finland at an altitude approximately 100 m over ground, each following the same
            trajectory plan as shown in Figure 3. We release this dataset
            for public use. The flights consist of drone images collected
            with a nadir-pointing camera as well as Inertial Measurement
            Unit (IMU) measurements, and we record autopilot output
            along with other telemetry data from an Ardupilot-based [29]
            drone flight controller. The flight takes place over an area that
            contains only a few buildings, and a large part of the trajectory takes place over a forest region, as well as above sea.
            This dataset represents flight of an UAV over a terrain that
            has naturally high ambiguity. We record this flight six times
            over many seasonal conditions.
          </p>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{kinnari2023sosslam,
  author    = {Kinnari, Jouko and Thomas, Annika and Lusk, Parker and Konda, Kota and How, Jonathan},
  title     = {SOS-SLAM: Segmentation for Open-Set SLAM in Unstructured Environments},
  journal   = {Arxiv preprint},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website adapted from the Nerfies templates, which is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            If you use the <a
              href="https://github.com/mit-acl/SOS-SLAM">source code</a> of this website,
            <a href="https://github.com/nerfies/nerfies.github.io"></a>link back to the Nerfies source code</a> in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
